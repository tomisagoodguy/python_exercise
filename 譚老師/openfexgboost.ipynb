{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy xgboost scikit-learn finlab openfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BP_ratio = data.get(\"price_earning_ratio:股價淨值比\")\n",
    "net_income = data.get('fundamental_features:經常稅後淨利')\n",
    "holder_equity = data.get('financial_statement:股東權益總額')\n",
    "roe = net_income/holder_equity\n",
    "# ... 添加所有其他數據獲取代碼 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def above_ma_rank(n):\n",
    "    return ((close > close.rolling(5).mean()).rolling(n).sum()).rank(axis=1, pct=True)\n",
    "\n",
    "\n",
    "def avg(n):\n",
    "    return (close / close.average(5)).rank(axis=1, pct=True)\n",
    "\n",
    "# ... 添加所有其他函數定義 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(functions, windows):\n",
    "    features = {}\n",
    "    for func_name, func in functions.items():\n",
    "        for window in windows.get(func_name, []):\n",
    "            feature_name = f\"{func_name}{window}\"\n",
    "            features[feature_name] = func(window)\n",
    "    return features\n",
    "\n",
    "\n",
    "# 定義函數和對應的時間窗口\n",
    "functions = {\n",
    "    'vol': vol.average,\n",
    "    'avg': avg,\n",
    "    # ... 添加所有其他函數 ...\n",
    "}\n",
    "\n",
    "windows = {\n",
    "    'vol': [20, 60],\n",
    "    'avg': [5, 20, 60, 120, 240],\n",
    "    # ... 添加所有其他窗口 ...\n",
    "}\n",
    "\n",
    "# 生成特徵\n",
    "features = create_features(functions, windows)\n",
    "\n",
    "# 添加其他特殊特徵\n",
    "additional_features = {\n",
    "    'cap': cap,\n",
    "    'roe': roe,\n",
    "    'amt': amt.average(5),\n",
    "    # ... 添加所有其他特殊特徵 ...\n",
    "}\n",
    "\n",
    "features.update(additional_features)\n",
    "\n",
    "# 使用 mlf.combine 合併所有特徵\n",
    "features = mlf.combine(features, resample='W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finlab.ml import label as mll\n",
    "\n",
    "labels = mll.excess_over_mean(features.index, resample='4W')\n",
    "\n",
    "is_train = features.index.get_level_values('datetime') < '2021-01-01'\n",
    "notna = (features.isna().sum(axis=1) == 0) & (labels.notna())\n",
    "train_x = features.loc[is_train & notna]\n",
    "train_y = labels.loc[is_train & notna]\n",
    "test_x = features.loc[~is_train & notna]\n",
    "test_y = labels.loc[~is_train & notna]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 4  # 您可以根據您的 CPU 核心數調整這個值\n",
    "\n",
    "ofe = OpenFE()\n",
    "features2 = ofe.fit(data=train_x.reset_index(drop=True),\n",
    "                    label=train_y.reset_index(drop=True),\n",
    "                    n_jobs=n_jobs, verbose=False, n_data_blocks=128, min_candidate_features=100)\n",
    "\n",
    "train_x2, test_x2 = transform(train_x.reset_index(drop=True),\n",
    "                              test_x.reset_index(drop=True),\n",
    "                              features2, n_jobs=1)\n",
    "train_x2.index = train_y.index\n",
    "test_x2.index = test_y.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "new_features = []\n",
    "for i, feature in enumerate(ofe.new_features_list):\n",
    "    formula = tree_to_formula(feature)\n",
    "    f_series = feature.calculate(features)\n",
    "\n",
    "    notna = f_series.notna() & labels.notna()\n",
    "    ic = np.corrcoef(f_series[notna].values, labels[notna].values)[0][1]\n",
    "\n",
    "    new_features.append((formula, ic))\n",
    "\n",
    "# 根據 IC 值排序，從高到低\n",
    "sorted_features = sorted(new_features, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# 顯示前10個特徵及其 IC 值\n",
    "for formula, ic in sorted_features[:10]:\n",
    "    print(f\"Formula: {formula}, IC: {ic}\")\n",
    "\n",
    "# 添加可視化\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(sorted_features)), [abs(ic) for _, ic in sorted_features])\n",
    "plt.title('Feature Importance (Absolute IC)')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('|IC|')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合併原始特徵和 OpenFE 生成的新特徵\n",
    "train_combined = pd.concat([train_x, train_x2], axis=1)\n",
    "test_combined = pd.concat([test_x, test_x2], axis=1)\n",
    "\n",
    "# 準備 XGBoost 數據集\n",
    "dtrain = xgb.DMatrix(train_combined, label=train_y)\n",
    "dtest = xgb.DMatrix(test_combined, label=test_y)\n",
    "\n",
    "# 設置 XGBoost 參數\n",
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "# 訓練 XGBoost 模型\n",
    "num_round = 100\n",
    "bst = xgb.train(params, dtrain, num_round, evals=[(dtest, \"Test\")])\n",
    "\n",
    "# 預測\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "# 評估模型\n",
    "rmse = np.sqrt(mean_squared_error(test_y, preds))\n",
    "print(f\"Test RMSE: {rmse}\")\n",
    "\n",
    "# 特徵重要性\n",
    "importance = bst.get_score(importance_type='gain')\n",
    "importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Top 10 important features:\")\n",
    "for feat, score in importance[:10]:\n",
    "    print(f\"{feat}: {score}\")\n",
    "\n",
    "# 添加特徵重要性可視化\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(importance)), [score for _, score in importance])\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析預測結果\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(test_y, preds)\n",
    "plt.plot([test_y.min(), test_y.max()], [\n",
    "         test_y.min(), test_y.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.show()\n",
    "\n",
    "# 計算並打印其他評估指標\n",
    "\n",
    "r2 = r2_score(test_y, preds)\n",
    "mae = mean_absolute_error(test_y, preds)\n",
    "\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# 討論結果\n",
    "print(\"結果分析：\")\n",
    "print(\"1. 模型性能：根據RMSE、R-squared和MAE，我們可以看出...\")\n",
    "print(\"2. 重要特徵：從特徵重要性分析中，我們可以發現...\")\n",
    "print(\"3. OpenFE的貢獻：通過比較原始特徵和OpenFE生成的新特徵，我們可以得出...\")\n",
    "print(\"4. 改進方向：基於以上分析，我們可以考慮以下幾個改進方向：\")\n",
    "print(\"   a. 調整XGBoost的超參數\")\n",
    "print(\"   b. 進一步優化特徵工程過程\")\n",
    "print(\"   c. 嘗試其他模型，如LightGBM或者集成方法\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
